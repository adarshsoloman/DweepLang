import torch
from transformers import MarianMTModel, MarianTokenizer
import os
from tqdm import tqdm

# Models to download
MODELS = {
    "en-hi": {
        "name": "Helsinki-NLP/opus-mt-en-hi",
        "info": {
            "dataset": "opus",
            "model": "transformer-align",
            "source": "English",
            "target": "Hindi",
            "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"
        }
    },
    "hi-en": {
        "name": "Helsinki-NLP/opus-mt-hi-en",
        "info": {
            "dataset": "opus",
            "model": "transformer",
            "source": "Hindi",
            "target": "English",
            "preprocessing": "normalization + tokenization + BPE"
        }
    }
}

BASE_PATH = "./models"

def print_model_info(direction, info):
    """Print model information"""
    print(f"\nüìã Model Information:")
    print(f"   Direction:      {info['source']} ‚Üí {info['target']}")
    print(f"   Dataset:        {info['dataset']}")
    print(f"   Architecture:   {info['model']}")
    print(f"   Preprocessing:  {info['preprocessing']}")

def download_and_save_model(model_name, save_folder, model_info):
    """Download Helsinki-NLP OPUS-MT model with progress"""
    
    os.makedirs(save_folder, exist_ok=True)
    
    print(f"\nüì• Downloading {model_name}")
    print(f"üìÇ Save location: {save_folder}")
    
    print_model_info(None, model_info)
    
    print("\n‚è≥ Downloading...")
    print("-" * 60)
    
    try:
        # Download tokenizer
        print("   [1/2] Downloading tokenizer...")
        with tqdm(total=100, desc="   Tokenizer", unit="%", ncols=70, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:
            tokenizer = MarianTokenizer.from_pretrained(model_name)
            pbar.update(50)
            tokenizer.save_pretrained(save_folder)
            pbar.update(50)
        print("   ‚úì Tokenizer saved")
        
        # Download model
        print("   [2/2] Downloading model weights...")
        with tqdm(total=100, desc="   Model", unit="%", ncols=70, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:
            model = MarianMTModel.from_pretrained(model_name)
            pbar.update(50)
            model.save_pretrained(save_folder)
            pbar.update(50)
        print("   ‚úì Model saved")
        
        # Get model size
        model_size = sum(
            os.path.getsize(os.path.join(save_folder, f)) 
            for f in os.listdir(save_folder) 
            if os.path.isfile(os.path.join(save_folder, f))
        )
        model_size_mb = model_size / (1024 * 1024)
        print(f"   ‚Ñπ Model size: {model_size_mb:.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"   ‚úó Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_model(model_path, direction):
    """Test the downloaded model"""
    print(f"\n   üß™ Testing model...")
    
    try:
        tokenizer = MarianTokenizer.from_pretrained(model_path)
        model = MarianMTModel.from_pretrained(model_path)
        
        # Test sentences
        tests = {
            "en-hi": [
                "Hello, how are you?",
                "Good morning!",
                "Thank you very much."
            ],
            "hi-en": [
                "‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?",
                "‡§∂‡•Å‡§≠ ‡§™‡•ç‡§∞‡§≠‡§æ‡§§!",
                "‡§¨‡§π‡•Å‡§§ ‡§¨‡§π‡•Å‡§§ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶‡•§"
            ]
        }
        
        test_sentences = tests.get(direction, ["Hello"])
        
        print(f"   Testing with {len(test_sentences)} sentences:")
        
        for i, test_text in enumerate(test_sentences, 1):
            inputs = tokenizer(test_text, return_tensors="pt", padding=True)
            with torch.no_grad():
                outputs = model.generate(**inputs, max_length=128)
            translation = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            print(f"   [{i}] {test_text}")
            print(f"       ‚Üí {translation}")
        
        print(f"   ‚úì All tests passed!")
        return True
        
    except Exception as e:
        print(f"   ‚úó Test failed: {e}")
        return False


if __name__ == "__main__":
    print("=" * 60)
    print("üì¶ Helsinki-NLP OPUS-MT Model Downloader")
    print("=" * 60)
    print("\nThis script will download:")
    for direction, model_data in MODELS.items():
        info = model_data["info"]
        print(f"  ‚Ä¢ {info['source']} ‚Üí {info['target']} ({model_data['name']})")
    print("\n" + "=" * 60)
    
    # Ask for confirmation
    proceed = input("\nü§î Proceed with download? (y/n): ").strip().lower()
    if proceed != 'y':
        print("‚ùå Download cancelled")
        exit(0)
    
    success_count = 0
    
    for direction, model_data in MODELS.items():
        model_name = model_data["name"]
        model_info = model_data["info"]
        save_path = os.path.join(BASE_PATH, direction)
        
        print("\n" + "=" * 60)
        print(f"üîÑ Processing: {direction}")
        print("=" * 60)
        
        # Check if already exists
        if os.path.exists(save_path) and os.listdir(save_path):
            print(f"üìÅ Model already exists at: {save_path}")
            user_input = input(f"   Re-download? (y/n): ").strip().lower()
            if user_input != 'y':
                print(f"   ‚è≠ Skipping download")
                
                # Test existing model
                if test_model(save_path, direction):
                    success_count += 1
                    print(f"   ‚úÖ {direction} verified!")
                continue
            else:
                # Remove old files
                import shutil
                shutil.rmtree(save_path)
                print(f"   üóë Removed old files")
        
        # Download
        if download_and_save_model(model_name, save_path, model_info):
            # Test the model
            if test_model(save_path, direction):
                success_count += 1
                print(f"   ‚úÖ {direction} complete!")
            else:
                print(f"   ‚ö† {direction} downloaded but test failed")
        else:
            print(f"   ‚ùå {direction} download failed")
    
    # Final summary
    print("\n" + "=" * 60)
    print("üìä Download Summary")
    print("=" * 60)
    print(f"‚úì Successfully downloaded: {success_count}/2 models")
    
    if success_count == 2:
        print("\n‚úÖ All models ready to use!")
        print(f"üìÇ Models location: {os.path.abspath(BASE_PATH)}")
        print("\n" + "=" * 60)
        print("üöÄ Next Steps:")
        print("=" * 60)
        print("1. Run the translation app:")
        print("   Windows: run.bat")
        print("   Linux/Mac: ./run.sh")
        print("\n2. Or test directly:")
        print("   python server/app.py")
    else:
        print("\n‚ö† Some models failed. Please check errors above.")
        print("üí° You can try running the script again.")
    
    print("=" * 60)